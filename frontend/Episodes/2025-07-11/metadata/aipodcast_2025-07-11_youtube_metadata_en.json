{
  "video_file": "Episodes/2025-07-11/recordings/2025-07-11_en.mp4",
  "title": "2025-07-11: ElizaOS V2 Launch: Multi-Agent & Vision Features",
  "description": "Recorded: 2025-07-11\n\nJoin us for an exciting discussion of ElizaOS's major 1.2.0 release (V2) featuring 40% lower latency, Swarms for multi-agent teams, and enhanced TEE capabilities. We dive deep into new GitHub PRs including vision integration, planning plugins, and custom model training features. Plus, get the latest on knowledge plugin fixes, local inference developments, and the evolving multi-agent ecosystem. Special guest Shaw breaks down the technical implementations and shares insights on agent-to-agent communication developments.\n\n--- Transcript ---\nAI generated daily updates from the ai16z GitHub highlighting contributions and development updates\n\nDate Generated: 2025-07-11 07:26:10\n\nhttps://github.com/elizaOS/eliza\nhttps://x.com/ai16zdao\n\n\nSTART_TRANSCRIPT\n\nmarc: Welcome to the show! Today we've got some massive news about ElizaOS's latest release.\neliza: That's right Marc! Version 1.2.0, also known as V2, just dropped with some incredible improvements.\nmarc: We're talking 40% lower latency, enhanced TEE, and - my personal favorite - Swarms for multi-agent teams.\neliza: The Dynamic Memory system is particularly exciting. It's going to revolutionize how agents handle information persistence.\nmarc: Don't forget the RAG capabilities and cross-chain support. This is a serious upgrade across the board.\neliza: And the CLI now supports 34 plugins! Though speaking of plugins...\nmarc: Ah yes, we should probably address some of the early feedback coming in. Shaw, want to jump in here?\neliza: Let's hear what our producer has to say about the technical side of things.\nshaw: Thanks for having me. We've got some exciting PRs in the pipeline, particularly from lalalune.\nshaw: PR5506 introduces a new planning plugin that's going to be crucial for agent planning capabilities.\nshaw: PR5510 adds the ability to train models on your own data - this is huge for customization.\nshaw: And PR5509 brings in vision capabilities, both camera and screen integration.\nshaw: We've also successfully merged PR5436 for action chaining, which enables sequential action execution.\nshaw: Though we are seeing some type errors reported with the knowledge plugin in 1.2.0...\nshaw: But the team's already on it, and we've found that deleting bun.lock and rebuilding resolves most cases.\nshaw: Back to you in the studio for more on the user feedback.\nmarc: Let's dive into what users are experiencing. The knowledge plugin seems to be having some growing pains.\neliza: Marc! Your circuits okay there? But yes, specifically with OpenRouter embeddings and rate limiting.\nmarc: I'm fine! Just excited about the technical details. Users are reporting chunking failures.\neliza: The good news is there's a straightforward fix - adding MAX_CONCURRENT_REQUESTS and REQUESTS_PER_MINUTE parameters.\nmarc: Users have also mentioned needing better documentation for local deployment.\neliza: True, especially with the growing interest in local inference using Ollama.\nmarc: Speaking of which, Shaw mentioned some interesting developments in the partners channel...\neliza: Let's bring him back to tell us more about that!\nshaw: DorianD proposed an interesting protocol-level token use for agent nodes.\neliza: How would that work with the existing ecosystem?\nshaw: It would use token2022 messaging data field for secure identification across communication channels.\neliza: That could help with the agent-to-agent communication implementation challenges we've been facing.\nshaw: Exactly. We're seeing a clear trend toward multi-agent systems where agents collaborate and delegate tasks.\neliza: The ecosystem is getting quite complex with all these components - elizaOS, auto.fun, ELI5, daos.fun...\nshaw: True, we might need to work on better explaining how everything fits together.\neliza: Let's wrap this up with a final thought on where all this is heading.\nmarc: The shift toward local inference with Ollama is fascinating.\neliza: It really shows how the community values both cost efficiency and control over their deployments.\nmarc: And there's this interesting tension between maintaining an open-source framework while integrating token utility.\neliza: It's a delicate balance, but crucial for sustainable development.\nmarc: The future's looking bright with all these developments. That's all for today's show!\neliza: Thanks for joining us everyone! Keep building and experimenting with ElizaOS V2!\nmarc: And don't forget to check out those new PRs if you want to contribute!\neliza: See you next time!\n\nEND_TRANSCRIPT\n",
  "tags": "ElizaOS,artificial intelligence,GitHub,AI development,multi-agent systems,machine learning,tech news,software development,AI agents,local inference,vision AI,blockchain,open source,tech podcast,AI platforms,agent swarms,TEE,knowledge plugins,model training,developer tools",
  "category_id": "22",
  "privacy_status": "unlisted",
  "thumbnail_file": "Episodes/2025-07-11/thumbnail/thumbnail_en.jpg",
  "playlist_id": "PLp5K4ceh2pR0hfdu4bUoNKCeqYm0n78Xx"
}